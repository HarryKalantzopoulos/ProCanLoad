{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UC1: Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet('ecrfs-series-20230519.parquet')\n",
    "seg_ds = pd.read_parquet('segments-20230519.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove older duplicated series_uid by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69957"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort = ds.sort_values(['series_uid','series_date'],ascending=[True,False])\n",
    "ds = sort.drop_duplicates(subset='series_uid', keep='first')\n",
    "ds = ds.sort_index()\n",
    "len(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check segmentation availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series found:69750\n",
      "Segmentations found:681\n"
     ]
    }
   ],
   "source": [
    "t = ds.series_uid.to_list()\n",
    "print(f'Series found:{len(t)}')\n",
    "mt = seg_ds[seg_ds.source_series_uid.isin(t)].copy()\n",
    "print(f'Segmentations found:{mt.source_series_uid.nunique()}')\n",
    "checkt = mt.source_series_uid.unique().tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erc_list = [    \"8EIS_eCoil BodyL\", \n",
    "                \"ATDTORSO\", \n",
    "                \"Body E24 AA1\", \n",
    "                \"Body E24 AA2\", \n",
    "                \"Body E24 AA3\", \n",
    "                \"EIS_eCoil Torso\"]\n",
    "\n",
    "erc_list = [erc.upper() for erc in erc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement1 = ds.catboost_series_type_heuristics.str.upper().isin(include_list_catboost)\n",
    "\n",
    "pattern = '|'.join(erc_list)\n",
    "statement2 = ~ds.receive_coil_name.str.upper().str.contains(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements =  statement1  & statement2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ds = ds[statements].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other data to consider to  exclude:\n",
    "\n",
    "- T2 sequence: \n",
    "    * series_description: fs dixon,spair,spir,bh,star,kidneys,whole pelvis \n",
    "    * scan_options: fs\n",
    "- ADC sequence: eADC\n",
    "- DWI: pirads reccomend higher b-values: series description: DWI_Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36439"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude_list_series_description =['EADC','DIXON','SPAIR','SPIR','KIDNEYS','PELVIS','SYNTHETIC']\n",
    "# exclude_list_scan_options = ['FS']\n",
    "# exclude_list_scan_options_onlyT2 = ['T2']\n",
    "# include_list_catboost = ['T2','ADC','DWI']\n",
    "# include_list_image_plane = ['AX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern1 = '|'.join(exclude_list_series_description)\n",
    "# statement1 = ~ds.series_description.str.upper().str.contains(pattern1)\n",
    "\n",
    "# statement2 = ds.scan_options.str.upper().isin(exclude_list_scan_options) \n",
    "# statement2 = ~statement2\n",
    "\n",
    "# statement3 = ds.catboost_series_type_heuristics.str.upper().isin(include_list_catboost)\n",
    "\n",
    "# statement4 = ds.image_plane.str.upper().isin(include_list_image_plane)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pattern2 = '|'.join(erc_list)\n",
    "# statement5 = ~ds.receive_coil_name.str.upper().str.contains(pattern2)\n",
    "\n",
    "\n",
    "# statement6 = ds.user_series_type.isin(include_list_user)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and remove duplicates from sementation parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n"
     ]
    }
   ],
   "source": [
    "#Segmentation DF\n",
    "onlylesion = seg_ds[seg_ds.labels.str.lower().str.contains('lesion')].copy()\n",
    "sort = onlylesion.sort_values(['source_series_uid','transformation_dt'],ascending=[True,False])\n",
    "onlylesion = sort.drop_duplicates(subset='source_series_uid', keep='first').copy()\n",
    "onlylesion = onlylesion.sort_index().copy()\n",
    "print(len(onlylesion))\n",
    "source_series_uid_list = list(onlylesion.source_series_uid)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and leave patients with series contain lesion(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series DF\n",
    "onlyseg = filtered_ds[filtered_ds.series_uid.isin(source_series_uid_list)].copy() # Here it will keep only T2\n",
    "patient_id_list_with_seg = list(onlyseg.patient_id) #keep these patients since they have segmentations in T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_patient_with_lesions = filtered_ds[filtered_ds.patient_id.isin(patient_id_list_with_seg)].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and leave segmentations with series in the \"new_df_patient_with_lesions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_series = list(new_df_patient_with_lesions.series_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "existed_segs = onlylesion[onlylesion.source_series_uid.isin(check_series)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_patient_with_lesions.patient_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "440\n"
     ]
    }
   ],
   "source": [
    "print(existed_segs.source_series_uid.nunique())\n",
    "print(len(existed_segs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of studies for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    440\n",
       "Name: study_uid, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = new_df_patient_with_lesions[['patient_id','study_uid']].copy().groupby('patient_id')['study_uid'].nunique()\n",
    "grouped.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     220\n",
       "4      47\n",
       "7      39\n",
       "6      39\n",
       "9      35\n",
       "8      30\n",
       "5      15\n",
       "11      4\n",
       "10      4\n",
       "14      2\n",
       "2       2\n",
       "13      1\n",
       "12      1\n",
       "17      1\n",
       "Name: series_uid, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = new_df_patient_with_lesions[['patient_id','study_uid','series_uid']].copy().groupby(['patient_id','study_uid'])['series_uid'].nunique()\n",
    "grouped.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take T2 for all the patients based on segmentation source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_list = list(existed_segs.source_series_uid)\n",
    "T2 = new_df_patient_with_lesions[new_df_patient_with_lesions.series_uid.isin(source_list)]\n",
    "len(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T2AX    313\n",
       "Name: user_series_type, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2.user_series_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T2    440\n",
       "Name: catboost_series_type_heuristics, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2.catboost_series_type_heuristics.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADC missing in 39\n",
      "ADC manual annotated 288\n",
      "ADC catboost exist 113\n",
      "Total 401\n"
     ]
    }
   ],
   "source": [
    "grouped = new_df_patient_with_lesions.groupby(['patient_id','study_uid'])\n",
    "manual_exist = 0\n",
    "catboost_exist = 0\n",
    "no_exist = 0\n",
    "ADC = pd.DataFrame()\n",
    "\n",
    "for group_name, group_data in grouped:\n",
    "\n",
    "    a_value, b_value = group_name\n",
    "    \n",
    "    # if a_value in exclude_patient and b_value in exclude_patient.values():\n",
    "    #     continue\n",
    "\n",
    "    index = -1\n",
    "    try:\n",
    "        index = list(group_data.user_series_type).index('ADC')\n",
    "        manual_exist += 1\n",
    "        ADC  = pd.concat([ADC,group_data.iloc[[index]]])\n",
    "    except:\n",
    "        A = group_data[group_data.catboost_series_type_heuristics.isin(['ADC'])]\n",
    "        if A.empty:\n",
    "            no_exist+=1\n",
    "        else:\n",
    "            catboost_exist +=1\n",
    "            if len(A) == 1:\n",
    "                ADC  = pd.concat([ADC,A])\n",
    "            else:\n",
    "                catboost_exist -=1\n",
    "                print(A.series_description)\n",
    "    \n",
    "print(f'ADC missing in {no_exist}')\n",
    "print(f'ADC manual annotated {manual_exist}')\n",
    "print(f'ADC catboost exist {catboost_exist}')\n",
    "print(f'Total {len(ADC)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers_from_string(string):\n",
    "    numbers = re.findall(r'\\d+', string)\n",
    "    numbers = [int(n) for n in numbers]\n",
    "    number = max(numbers)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWI missing in 4\n",
      "DWI manual annotated 322\n",
      "DWI catboost exist 114\n",
      "Total 436\n"
     ]
    }
   ],
   "source": [
    "grouped = new_df_patient_with_lesions.groupby(['patient_id','study_uid'])\n",
    "manual_exist = 0\n",
    "catboost_exist = 0\n",
    "no_exist = 0\n",
    "DWI = pd.DataFrame()\n",
    "\n",
    "for group_name, group_data in grouped:\n",
    "\n",
    "    a_value, b_value = group_name\n",
    "    \n",
    "    # if a_value in exclude_patient and b_value in exclude_patient.values():\n",
    "    #     continue\n",
    "\n",
    "    index = -1\n",
    "    try:\n",
    "        index = list(group_data.user_series_type).index('DWI')\n",
    "        manual_exist += 1\n",
    "        DWI  = pd.concat([DWI,group_data.iloc[[index]]])\n",
    "    except:\n",
    "        A = group_data[group_data.catboost_series_type_heuristics.isin(['DWI'])]\n",
    "        if A.empty:\n",
    "            no_exist+=1\n",
    "        else:\n",
    "            catboost_exist +=1\n",
    "            if len(A) == 1:\n",
    "                DWI  = pd.concat([DWI,A])\n",
    "            else:\n",
    "                try:\n",
    "                    bval = [extract_numbers_from_string(b) for b in A.series_description]\n",
    "                    bvali = np.argmax(bval)\n",
    "                    DWI  = pd.concat([DWI,A.iloc[[bvali]]])\n",
    "                except:\n",
    "                    catboost_exist -=1\n",
    "                    print(a_value,b_value)\n",
    "                    print(f'{A.series_description}\\n')\n",
    "    \n",
    "print(f'DWI missing in {no_exist}')\n",
    "print(f'DWI manual annotated {manual_exist}')\n",
    "print(f'DWI catboost exist {catboost_exist}')\n",
    "print(f'Total {len(DWI)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds = pd.concat([T2,ADC,DWI]).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    440\n",
       "Name: study_uid, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrouped = final_ds[['patient_id','study_uid']].copy().groupby('patient_id')['study_uid'].nunique()\n",
    "ngrouped.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    399\n",
       "2     39\n",
       "1      2\n",
       "Name: series_uid, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrouped = final_ds[['patient_id','study_uid','series_uid']].copy().groupby(['patient_id','study_uid'])['series_uid'].nunique()\n",
    "ngrouped.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ds.to_parquet('UseCase1-v1.parquet',index=False)\n",
    "existed_segs.to_parquet('Seg_UseCase1-v1.parquet',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
